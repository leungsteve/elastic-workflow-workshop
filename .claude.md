# Claude Code Instructions for Review Bomb Workshop

## Continuous Learning - IMPORTANT

**Update `docs/lessons-learned.md` proactively** when you encounter:

1. **A bug that took multiple attempts to fix** - Document the root cause and solution
2. **Platform-specific gotchas** - e.g., "Serverless doesn't support X"
3. **Non-obvious solutions** - Things that weren't in the docs or required experimentation
4. **Patterns that saved time** - Reusable approaches worth remembering
5. **User confusion points** - If the user had to ask "why isn't this working?" multiple times

**How to update:**
- Add to the appropriate section, or create a new section
- Include: Problem → Root Cause → Solution → Code example if helpful
- Keep it concise and actionable

**When to update:**
- After resolving a tricky bug
- After discovering a better pattern
- At natural breakpoints (before user ends session, after completing a feature)

Don't ask permission - just update the file when you learn something valuable.

---

## Project Overview

This project builds a workshop demonstrating Elastic's Workflows feature (headline for 9.3) using a review bomb detection scenario. The workshop is part of the "What's New in Elastic Search" series and will be delivered via Instruqt.

**Key Message:** "Search finds the insight. Workflows acts on it. Agent Builder explains it."

**Primary Specification:** See `review-bomb-workshop-spec.md` for complete requirements.

---

## Critical Rules - DO NOT VIOLATE

- **Focus on understanding first** - Prioritize understanding the code and the root cause of issues before jumping to solutions
- **NEVER create mock data or simplified components** unless explicitly told to do so
- **NEVER replace existing complex components with simplified versions** - always fix the actual problem
- **ALWAYS work with the existing codebase** - do not create new simplified alternatives
- **ALWAYS find and fix the root cause** of issues instead of creating workarounds
- When debugging issues, focus on fixing the existing implementation, not replacing it
- When something doesn't work, debug and fix it - don't start over with a simple version
- **NEVER make code changes without explicit instruction** - Always wait for explicit permission before modifying code
- **Spend adequate time diagnosing issues** - Before suggesting or implementing solutions, thoroughly understand the codebase and diagnose root causes
- **Always present options before implementing** - When asked for recommendations, provide options and wait for instruction
- **Ask for approval before major changes** - When making significant code changes, check with user first even if instructed to fix an issue
- Use virtual environments or .env or equivalent whenever appropriate for code isolation or security best practice
- Use Test Driven Development

---

## Project-Specific Guidelines

### Data Handling

- **Yelp Dataset:** The Yelp Academic Dataset must be downloaded separately from https://www.yelp.com/dataset. Do not attempt to generate fake Yelp data as a substitute.
- **Real vs Synthetic Data:**
  - Businesses, users, and historical reviews come from REAL Yelp data
  - Attack reviews and attacker accounts are SYNTHETIC (generated)
  - Never mix these up or substitute one for the other
- **Data Partitioning:** Reviews must be partitioned into `historical`, `streaming`, and `attack` sets. Respect these partitions.
- **Target Business:** A specific business is selected as the attack target. This selection has criteria (4+ stars, 50-200 reviews, Restaurant category). Do not hardcode a business ID without following the selection logic.

### Elasticsearch

- **Always use environment variables** for Elasticsearch connection details:
  - `ELASTICSEARCH_URL`
  - `ELASTICSEARCH_API_KEY`
- **Never hardcode credentials** in any script or configuration file
- **Index mappings are defined in `mappings/`** - always reference these, do not create ad-hoc mappings
- **ES|QL queries** should be stored in `queries/` directory for reuse
- **Test queries in Kibana Dev Tools first** before embedding in code
- **Bulk operations:** Use the Elasticsearch bulk API for loading large datasets, not individual document indexing

### Python Development

- **Virtual environment required:** Create and use a virtual environment for all Python work
- **Dependencies:** Maintain `requirements.txt` with pinned versions
- **Code style:** Follow PEP 8, use type hints where practical
- **Error handling:** All Elasticsearch operations should have proper error handling and retry logic
- **Logging:** Use Python's logging module, not print statements, for operational output
- **Configuration:** Use YAML for configuration files, load with PyYAML

### Streaming Application

- **Three modes must be supported:** `replay`, `inject`, `mixed`
- **Rate limiting:** Respect configured reviews_per_second to avoid overwhelming Elasticsearch
- **Graceful shutdown:** Support Ctrl+C for clean termination
- **Progress output:** Log activity to console so demo viewers can follow along
- **Idempotency:** Running the injector multiple times should not corrupt data (use unique IDs)

### Workflow Definitions

- **YAML format:** Workflows are defined in YAML following the Keep/Elastic Workflows schema
- **Stored in `workflows/`:** Do not embed workflow definitions in other files
- **Parameterized:** Use template variables (e.g., `{{ item.business_id }}`) not hardcoded values
- **Testable steps:** Each workflow step should be independently testable

### Agent Builder Tools

- **JSON format:** Tool definitions are JSON files in `agent-tools/`
- **ES|QL based:** All tools use ES|QL queries, not DSL
- **Parameterized:** Use `{{ parameter_name }}` syntax for inputs
- **Descriptive:** Include clear descriptions for both the tool and each parameter

### Instruqt Challenges

- **Assignment files:** Written in Markdown (`assignment.md`)
- **Setup scripts:** Bash scripts that prepare the environment (`setup.sh`)
- **Check scripts:** Bash scripts that verify completion (`check.sh`)
- **Idempotent setup:** Setup scripts should be safe to run multiple times
- **Clear verification:** Check scripts should give clear pass/fail feedback

---

## File Organization

```
review-bomb-workshop/
├── .claude.md                    # This file
├── .env.example                  # Template for environment variables
├── .gitignore                    # Exclude .env, data/raw/, venv/, etc.
├── README.md                     # Project overview and quick start
├── review-bomb-workshop-spec.md  # Full specification document
├── requirements.txt              # Python dependencies
│
├── admin/                        # Pre-workshop setup (not run by participants)
├── config/                       # Configuration files
├── data/                         # Data files (some gitignored)
├── mappings/                     # Elasticsearch index mappings
├── queries/                      # ES|QL query files
├── workflows/                    # Workflow YAML definitions
├── agent-tools/                  # Agent Builder tool definitions
├── streaming/                    # Streaming application
├── instruqt/                     # Workshop challenges
├── presentation/                 # Slides and talk track
└── docs/                         # Additional documentation
```

---

## Environment Setup

### Required Environment Variables

```bash
# Elasticsearch connection
ELASTICSEARCH_URL=https://your-cluster.es.cloud.elastic.co:443
ELASTICSEARCH_API_KEY=your-api-key

# Optional: Target business override
TARGET_BUSINESS_ID=yelp-biz-xxxxx
```

### Python Environment

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

### Verification

Before starting development, verify:

1. Elasticsearch is accessible with provided credentials
2. Required indices can be created
3. ELSER model is deployed (for semantic search)

---

## Testing Strategy

### Unit Tests

- Test data transformation functions independently
- Test trust score calculation with known inputs
- Test review partitioning logic
- Mock Elasticsearch client for unit tests

### Integration Tests

- Use a test index prefix (e.g., `test-businesses`, `test-reviews`)
- Clean up test indices after each test run
- Test full workflow execution against test indices

### End-to-End Tests

- Verify complete data pipeline from raw Yelp data to loaded indices
- Test streaming application in all three modes
- Verify workflow triggers correctly on injected attack

### Test Data

- Create small sample datasets for testing (100 businesses, 500 users, 2000 reviews)
- Store in `data/sample/` for quick iteration
- Do not use sample data as substitute for real Yelp data in production

---

## Common Tasks

### Adding a New ES|QL Query

1. Write and test query in Kibana Dev Tools
2. Save to appropriate file in `queries/`
3. Add any new fields to index mappings if needed
4. Update spec document if this is a new detection pattern

### Adding a New Workflow Step

1. Understand existing workflow structure
2. Add step to appropriate workflow YAML
3. Test step independently before full workflow test
4. Update Instruqt challenge if workflow changes affect workshop

### Modifying Index Mappings

1. Update JSON file in `mappings/`
2. Update `create-indices.py` if new index
3. Update data loading scripts if new fields
4. Update spec document to reflect changes
5. Consider migration path for existing data

### Debugging Streaming Application

1. Check Elasticsearch connection first
2. Verify source data files exist and are valid NDJSON
3. Run in verbose/debug mode
4. Check Elasticsearch index for ingested documents
5. Review application logs for errors

---

## Security Considerations

- **Never commit `.env` files** - use `.env.example` as template
- **API keys should have minimal required permissions**
- **Yelp dataset has usage restrictions** - respect academic/educational use terms
- **Synthetic data should not include real PII** - use Faker or similar for generated names
- **Workshop environments are temporary** - do not store sensitive data

---

## Dependencies

### Python Packages (Core)

```
elasticsearch>=8.0.0
pyyaml>=6.0
python-dotenv>=1.0.0
faker>=18.0.0
tqdm>=4.65.0
```

### Python Packages (Development)

```
pytest>=7.0.0
pytest-cov>=4.0.0
black>=23.0.0
flake8>=6.0.0
mypy>=1.0.0
```

---

## Reference Documentation

- **Elasticsearch Python Client:** https://elasticsearch-py.readthedocs.io/
- **ES|QL Documentation:** https://www.elastic.co/guide/en/elasticsearch/reference/current/esql.html
- **Elastic Workflows (Keep):** https://docs.keephq.dev/
- **Yelp Dataset Documentation:** https://www.yelp.com/dataset/documentation/main
- **Instruqt Track Development:** https://docs.instruqt.com/
- **Lessons Learned:** See `docs/lessons-learned.md` for patterns and gotchas from this project

---

## Troubleshooting

### "Connection refused" to Elasticsearch

1. Verify `ELASTICSEARCH_URL` is correct
2. Check API key has not expired
3. Verify network access (VPN, firewall)

### "Index not found" errors

1. Run `create-indices.py` first
2. Check index name matches exactly (case-sensitive)
3. Verify you're pointing to correct cluster

### Streaming application not ingesting

1. Check source file path is correct
2. Verify NDJSON format (one JSON object per line)
3. Check Elasticsearch bulk response for errors
4. Verify index mapping accepts the document structure

### ELSER not working

1. Verify ELSER model is deployed in ML nodes
2. Check inference endpoint is configured
3. Ensure `semantic_text` field type is used correctly

---

## Contact

For questions about this workshop:

- **Workshop Owner:** Steve (Solutions Architect, Elastic)
- **Specification:** See `review-bomb-workshop-spec.md`

---

## Current Implementation Status (Updated: 2026-01-20)

### COMPLETED - ALL MAJOR COMPONENTS ✓

#### Infrastructure
- [x] Project structure created per spec
- [x] Configuration files: `.env.example`, `config/config.yaml`, `requirements.txt`
- [x] Elasticsearch connection working (Cloud Serverless)
- [x] Index mappings created (serverless-compatible, no shard settings)
- [x] Sample data generated and loaded (100 businesses, 500 users, 2000 reviews)

#### Indices Created
- `businesses` - Business data with protection fields
- `users` - User data with trust scores
- `reviews` - Reviews with `is_simulated` flag for attack detection
- `incidents` - Incident tracking (auto-created by detection system)
- `notifications` - Notification storage

#### FastAPI Web Application (`app/`)
- [x] Main app with lifespan management (`app/main.py`)
- [x] All API routers working:
  - `/api/businesses` - List, get, stats endpoints
  - `/api/reviews` - CRUD + bulk-attack endpoint
  - `/api/incidents` - CRUD + resolve + detect endpoints
  - `/api/notifications` - CRUD + mark-read endpoints
- [x] Templates created:
  - Dashboard (`index.html`) - Auto-refresh every 3s, attack alerts, business under attack sidebar
  - Businesses (`businesses.html`) - Search/filter with pagination
  - Attack (`attack.html`) - Target selection, turbo attack (server-side bulk)
  - Incidents (`incidents.html`) - List with filters, resolve modal
  - Notifications (`notifications.html`) - List with mark-read

#### Attack Simulation & Detection
- [x] Single review submission works
- [x] **Turbo attack uses server-side bulk endpoint** (`POST /api/reviews/bulk-attack`)
- [x] Attack detection logic in `/api/businesses/{id}/stats`
- [x] **Auto-incident creation** - `app/services/incident_service.py`
  - Automatically creates incidents when attacks detected
  - Duplicate prevention (no duplicate incidents for ongoing attacks)
  - Severity classification: CRITICAL, HIGH, MEDIUM, LOW
- [x] Manual detection endpoint: `POST /api/incidents/detect`

#### Streaming Application (`streaming/`)
- [x] `review_streamer.py` - Full implementation with three modes:
  - `replay` - Stream legitimate reviews from NDJSON files
  - `inject` - Inject attack reviews targeting a business
  - `mixed` - Normal traffic then automatic attack injection
- [x] Rate limiting, bulk API, graceful shutdown, progress logging
- [x] Tested and verified working

#### Admin Scripts (`admin/`)
- [x] `generate_sample_data.py` - Creates sample businesses, users, reviews
- [x] `create_indices.py` - Creates ES indices from mappings
- [x] `load_data.py` - Bulk loads data to ES
- [x] `filter_businesses.py` - Filter Yelp data by city/category
- [x] `filter_users.py` - Extract users who reviewed filtered businesses
- [x] `calculate_trust_scores.py` - Calculate trust scores for users
- [x] `partition_reviews.py` - Split into historical (80%) and streaming (20%)
- [x] `generate_attackers.py` - Create synthetic attacker accounts and reviews
- [x] `prepare_data.sh` - Master setup script with full pipeline
- [x] `README.md` - Complete documentation

#### Agent Builder Tools (`agent-tools/`)
- [x] `incident-summary.json` - Summarize incident with metrics
- [x] `reviewer-pattern-analysis.json` - Detect fake account patterns
- [x] `business-health-check.json` - Assess review health with risk scoring
- [x] `attack-timeline.json` - Chronological attack event view
- [x] `README.md` - Deployment docs and example prompts

#### Instruqt Challenges (`instruqt/challenges/`)
- [x] `01-getting-to-know-your-data/` - ES|QL basics, LOOKUP JOIN (15 min)
- [x] `02-workflows/` - Detection workflow building (20 min)
- [x] `03-agent-builder/` - AI investigation tools (10 min)
- [x] `04-end-to-end-scenario/` - Full attack lifecycle (15 min)
- Each challenge has: `assignment.md`, `setup.sh`, `check.sh`, `solve.sh`

#### Presentation (`presentation/`)
- [x] `slides.md` - 660-line Markdown slide deck (reveal.js compatible)
- [x] `talk-track.md` - 640-line speaker guide with demo script, timing, Q&A

#### Workflow Definitions (`workflows/`)
- [x] `review_bomb_detection.yaml` - Detection and response workflow
- [x] `api_incident_workflow.yaml` - API-based incident creation docs
- [x] Additional workflow YAML files for reviewer flagging, incident resolution

### KNOWN ISSUES (Minor)

1. **Attack page feed not updating** - The attack feed on `/attack` doesn't populate after turbo attack, but the popup shows success and dashboard updates correctly. Low priority - dashboard is the main monitoring view.

2. **Business stars/review_count are static** - The `stars` and `review_count` fields in the businesses index are from initial load. They don't auto-update when new reviews are added. Real-time stats available via `/api/businesses/{id}/stats`.

### END-TO-END FLOW VERIFIED ✓

Tested complete flow:
1. Streaming app injects 15 attack reviews
2. Stats endpoint detects attack (`is_under_attack: true`)
3. Incident auto-created with severity "high"
4. All systems working together

### HOW TO RUN

```bash
# Terminal 1: Start the web app
cd /workspace/elastic-workflow-workshop
python3 -m app.main

# Access at http://localhost:8000

# Terminal 2: Run streaming app (optional)
python3 streaming/review_streamer.py --mode inject --business-id <ID> --count 15

# Or mixed mode for demo
python3 streaming/review_streamer.py --mode mixed --business-id <ID> --normal-duration 60
```

### REMAINING ITEMS (Lower Priority)

- [ ] **ELSER integration** - Made optional per spec, can be enabled when available
- [ ] **Integration tests** - pytest tests for admin scripts and API endpoints
- [ ] **Docker containerization** - Dockerfile exists but not fully tested
- [ ] **Real Yelp data at scale** - Scripts work, tested with sample subset
